---
layout: home
hero:
  name: AgentEval
  text: AI Agent Evaluation Framework
  tagline: Test, judge, and track AI coding agents with Vitest-like DX
  actions:
    - theme: brand
      text: Get Started
      link: /guide/getting-started
    - theme: alt
      text: API Reference
      link: /api/test
features:
  - title: ğŸ§ª Vitest-like DX
    details: Familiar test() / expect() API designed specifically for evaluating AI agents.
  - title: ğŸ”’ Git Isolation
    details: Automatic git reset between test runs guarantees pristine environments.
  - title: âš–ï¸ LLM-as-a-Judge
    details: Structured evaluation via Anthropic, OpenAI, or local Ollama models.
  - title: ğŸ“Š SQLite Ledger
    details: Local, privacy-first historical tracking. No data leaves your machine.
  - title: ğŸ–¥ï¸ Dashboard API
    details: "Run `agenteval view` to launch a local API server and explore results."
  - title: ğŸ—ï¸ SOLID Architecture
    details: Modular, extensible design. Add providers without touching core logic.
---
